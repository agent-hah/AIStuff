{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\solimhm\\appdata\\roaming\\python\\python38\\site-packages (2.0.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\solimhm\\appdata\\roaming\\python\\python38\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\program files\\python38\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\program files\\python38\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\program files\\python38\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\program files\\python38\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "WARNING: You are using pip version 21.1.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Program Files\\Python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in c:\\users\\solimhm\\appdata\\roaming\\python\\python38\\site-packages (3.7.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\solimhm\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\program files\\python38\\lib\\site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\solimhm\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\solimhm\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\solimhm\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in c:\\program files\\python38\\lib\\site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\program files\\python38\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\solimhm\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib) (4.55.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\solimhm\\appdata\\roaming\\python\\python38\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\program files\\python38\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\program files\\python38\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\program files\\python38\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "WARNING: You are using pip version 21.1.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Program Files\\Python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\solimhm\\appdata\\roaming\\python\\python38\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\program files\\python38\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\solimhm\\appdata\\roaming\\python\\python38\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\solimhm\\appdata\\roaming\\python\\python38\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\solimhm\\appdata\\roaming\\python\\python38\\site-packages (from scikit-learn) (1.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "WARNING: You are using pip version 21.1.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Program Files\\Python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\program files\\python38\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\program files\\python38\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (56.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.25.5)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: packaging in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.68.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\program files\\python38\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\program files\\python38\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.45.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\program files\\python38\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\program files\\python38\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\program files\\python38\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.36.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\program files\\python38\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\program files\\python38\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.0.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\program files\\python38\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\program files\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\program files\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\program files\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\program files\\python38\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\program files\\python38\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\program files\\python38\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.20.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\program files\\python38\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\program files\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\program files\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\program files\\python38\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\program files\\python38\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "WARNING: You are using pip version 21.1.1; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Program Files\\Python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enables array (matrix) manipulation\n",
    "import numpy as np\n",
    "\n",
    "# Enables people to build and train neural networks\n",
    "import tensorflow as tf\n",
    "\n",
    "# Simplifies the process of building neural networks, abstracting many complex functions\n",
    "from tensorflow import keras\n",
    "\n",
    "# Enables data visualization with graphs, charts, etc.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Enables people to easily use data in a program for csv, excel, and text data files\n",
    "import pandas as pd\n",
    "\n",
    "# Enables people to modify, execute, and find items in os\n",
    "import os\n",
    "\n",
    "# Used to simplfy process of Data Analysis\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This optimizer and loss function will be used to train the neural network\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense, BatchNormalization, MaxPooling2D, Dropout\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String\n",
    "name = \"Aurchie\"\n",
    "\n",
    "# Integer\n",
    "age = 30\n",
    "\n",
    "# Float\n",
    "balance = 3.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "My name is Aurchie. I am 30 years old. I have $3.08 in my bank account.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('Aurchie', 30, 3.08)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# This shows how to include variables in a long-form output text\n",
    "# Variables stay across code blocks in Google Colab\n",
    "print(f'My name is {name}. I am {age} years old. I have ${balance} in my bank account.')\n",
    "\n",
    "#If on last line of a google colab cell, simply typing a variable name will display the value of the variable(s) or object(s)\n",
    "name, age, balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Armor\n1-22-1974\n1-22-1974\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 2) dtype=int32, numpy=\n",
       "array([[2, 0],\n",
       "       [1, 0]])>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "#This shows a list\n",
    "inventory = [\"Sword\",\"Shield\",\"Armor\",\"Potion\"]\n",
    "print(inventory[2])\n",
    "\n",
    "#This shows a dictionary\n",
    "date_of_birth = {\n",
    "    \"James\": '1-22-1974',\n",
    "    \"John\" : '4-17-1968'\n",
    "}\n",
    "\n",
    "#Looking up what James's birthday would be in two different ways\n",
    "print(date_of_birth[\"James\"]) #Would give an exception if key is not found\n",
    "print(date_of_birth.get(\"James\")) # Would return None if key is not found\n",
    "\n",
    "#This shows a tensor\n",
    "tensor = tf.Variable([[2,0],[1,0]])\n",
    "tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Aurchie's current balance is $3.08.\nAurchie deposited 5 dollars to her bank account. Aurchie's current balance is $8.08.\nAurchie withdrew 4 dollars from her bank account. Aurchie's current balance is $4.08.\nAurchie's balance doubled. She now has $8.16 in her bank account.\nAurchie's balance halved. She now has $4.08 in her bank account.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{name}'s current balance is ${balance}.\")\n",
    "\n",
    "#Addition\n",
    "balance += 5\n",
    "print(f\"{name} deposited 5 dollars to her bank account. {name}'s current balance is ${balance}.\")\n",
    "\n",
    "#Subtraction\n",
    "balance -= 4\n",
    "print(f\"{name} withdrew 4 dollars from her bank account. {name}'s current balance is ${balance}.\")\n",
    "\n",
    "#Multiplication\n",
    "balance *= 2\n",
    "print(f\"{name}'s balance doubled. She now has ${balance} in her bank account.\")\n",
    "\n",
    "#Division\n",
    "balance /= 2\n",
    "print(f\"{name}'s balance halved. She now has ${balance} in her bank account.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "# Initializes a list\n",
    "numbers = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "# Duplicates the list\n",
    "same_numbers = numbers[:]\n",
    "\n",
    "# Uses a for loop to add 5 to every number in the list\n",
    "# The len() function gives the length of a list\n",
    "# The range() function allows index to go from 0 (inclusive) to the list length (exclusive)\n",
    "for index in range(len(same_numbers)):\n",
    "  same_numbers[index] += 5\n",
    "print(same_numbers)\n",
    "\n",
    "# List Comprehensions use for loops inside a list in order to generate values efficiently\n",
    "same_numbers = [i+5 for i in numbers]\n",
    "print(same_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With all of your current knowledge, make a list of numbers, and multiply each element in the list by 2^(index). Keep in mind there are multiple ways to go about this same problem, so the solution given does not have to match the solution that you have written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will preprocess all the RGB values in the input image\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "\n",
    "    # Load the JPEG image from the directory\n",
    "    image = tf.io.read_file(image_path)\n",
    "\n",
    "    # Get the RGB values of each image\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.cast(image,tf.float32)\n",
    "\n",
    "    # Normalize each RGB value to be between [0, 1] instead of [0, 255]\n",
    "    # This is important because training generally works better with values between 0 and 1\n",
    "    image = image / 255\n",
    "\n",
    "    # The new normalized RGB values of the image are returned\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will preprocess all the labels (the animal names)\n",
    "\n",
    "def preprocess_label(animal_name):\n",
    "\n",
    "    # Instead of using the actual animal names, it will be easier to simply use a corresponding number for each label\n",
    "    # This type of data structure below is a dictionary, here with five \"Key-Value pairs\"\n",
    "    label_to_number = {\"bee\": 0,\n",
    "                       \"bison\": 1,\n",
    "                       \"beetle\": 2,\n",
    "                       \"boar\": 3,\n",
    "                       \"butterfly\": 4}\n",
    "\n",
    "    # Assign a number based on the animal name (which was the input to this function)\n",
    "    # The animal name is the \"Key\" that is associated with the number \"Value\" in the dictionary\n",
    "    number = label_to_number[animal_name]\n",
    "    print(animal_name,number)\n",
    "\n",
    "    # The new number is returned\n",
    "    return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will use the previous two functions in order to preprocess every image and every associated label\n",
    "\n",
    "def preprocess_all_images(dir,total_train_percentage,image_per_category=60):\n",
    "  # These (currently empty) lists will be filled with the preprocessed data after calling the functions\n",
    "  images = []\n",
    "  labels = []\n",
    "\n",
    "  # Each different type of animal is stored in a different folder, so preprocess data one folder at a time\n",
    "  folders = []\n",
    "  for folder in os.listdir(dir):\n",
    "    folders.append(folder)\n",
    "  for i in folders:\n",
    "    for file in os.listdir(dir + \"/\" + i):\n",
    "      images.append(preprocess_image(dir+\"/\"+i+\"/\"+file))\n",
    "      labels.append(preprocess_label(i))\n",
    "\n",
    "  # This long line calls the sklearn function we imported in order to make the split between training and testing data\n",
    "  train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "        images, labels, train_size=total_train_percentage/100, random_state=42, stratify=labels\n",
    "    )\n",
    "\n",
    "  # Now we have lists of normalized images and numeric labels (since we just ran all the preprocessing)\n",
    "  # We need to convert the lists into tensors so that we can operate on them using TensorFlow when we train the model\n",
    "  train_images = tf.convert_to_tensor(train_images)\n",
    "  train_labels = tf.convert_to_tensor(train_labels)\n",
    "  test_images = tf.convert_to_tensor(test_images)\n",
    "  test_labels = tf.convert_to_tensor(test_labels)\n",
    "\n",
    "  # The training and testing tensors are returned\n",
    "  return train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "bee 0\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "beetle 2\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "bison 1\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "boar 3\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n",
      "butterfly 4\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(TensorShape([240, 75, 100, 3]), TensorShape([240]))"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Define important variables that can easily be changed if necessary (REMEMBER TO CHANGE THE USERNAME)\n",
    "mother_dir = 'C://users/solimhm/Downloads/AnimalPictures/AnimalPictures'\n",
    "\n",
    "total_train_percentage = 80\n",
    "images_per_category = 60\n",
    "categories = 5\n",
    "\n",
    "# Run the preprocess_all_images function using the variables above\n",
    "train_image, train_label, test_image, test_label = preprocess_all_images(mother_dir,total_train_percentage,images_per_category)\n",
    "train_image.shape, train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define our model using Sequential() which simply means that computations proceed forward\n",
    "# The inputs are passed in, computations are done in the first hidden layer, then the second, etc. until the output layer\n",
    "model = Sequential([\n",
    "    # The convolutional and flatten layers allow for more efficient image processing\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(75, 100, 3)),\n",
    "    Flatten(),\n",
    "    # The dense layers are the actual neural network layers with nodes and activation functions\n",
    "    Dense(32, activation='relu', name='HiddenLayer'), # Hidden layer with 32 nodes - feel free to change this hyper-parameter\n",
    "    Dense(5, activation='softmax')  # Output layer that should have num_classes (in our case, 5) units\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(240, 75, 100, 3) (240,)\n",
      "Epoch 1/25\n",
      "C:\\Program Files\\Python38\\lib\\site-packages\\keras\\src\\backend.py:5714: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n",
      "8/8 [==============================] - 1s 45ms/step - loss: 4.1646\n",
      "Epoch 2/25\n",
      "8/8 [==============================] - 0s 44ms/step - loss: 1.7653\n",
      "Epoch 3/25\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.2887\n",
      "Epoch 4/25\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 1.0544\n",
      "Epoch 5/25\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.8456\n",
      "Epoch 6/25\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.6768\n",
      "Epoch 7/25\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.4970\n",
      "Epoch 8/25\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.3730\n",
      "Epoch 9/25\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.2146\n",
      "Epoch 10/25\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.1324\n",
      "Epoch 11/25\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0853\n",
      "Epoch 12/25\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0538\n",
      "Epoch 13/25\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0273\n",
      "Epoch 14/25\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0161\n",
      "Epoch 15/25\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0101\n",
      "Epoch 16/25\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0066\n",
      "Epoch 17/25\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0078\n",
      "Epoch 18/25\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0072\n",
      "Epoch 19/25\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0079\n",
      "Epoch 20/25\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0043\n",
      "Epoch 21/25\n",
      "8/8 [==============================] - 0s 48ms/step - loss: 0.0027\n",
      "Epoch 22/25\n",
      "8/8 [==============================] - 0s 49ms/step - loss: 0.0022\n",
      "Epoch 23/25\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0017\n",
      "Epoch 24/25\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0015\n",
      "Epoch 25/25\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.0014\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d2d3c6eeb0>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# The learning rate hyper-parameter controls how fast the model learns.\n",
    "# Think of the learning rate as step size when trying to reach a particular optimal point\n",
    "# The perfect learning rate will get you there fastest, without overshooting or taking too long\n",
    "# For most applications, 0.001 or 0.0001 will work well\n",
    "learning_rate = 0.001\n",
    "\n",
    "# We need to define the loss function and optimizer for our model\n",
    "# The compile() function allows the model to be trained afterward\n",
    "model.compile(\n",
    "    loss = SparseCategoricalCrossentropy(learning_rate),\n",
    "    optimizer = Adam()\n",
    ")\n",
    "\n",
    "# Check the dimensions of our training data to ensure it is ready to use\n",
    "print(train_image.shape, train_label.shape)\n",
    "\n",
    "# Train the model using the fit() function for 25 epochs\n",
    "# Epochs is another hyper-parameter that controls the iterations over the training data\n",
    "# More epochs will fit the model closer and closer to the training data; however, too many epochs can lead to overfitting\n",
    "# Overfitting occurs when a model focuses too much on the training data and not being able to generalize to the testing data\n",
    "model.fit(train_image, train_label, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 1.2268\n"
     ]
    }
   ],
   "source": [
    "# This runs the model on all the testing data (consisting of the images and labels)\n",
    "results = model.evaluate(test_image, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_to_label = {0: \"bee\",\n",
    "                    1: \"bison\",\n",
    "                    2: \"beetle\",\n",
    "                    3: \"boar\",\n",
    "                    4: \"butterfly\"}\n",
    "\n",
    "def visualize_results(image,label):\n",
    "  # Run the model on the image given to this function using the built-in predict() function\n",
    "  predictions = model.predict(tf.expand_dims(image,axis=0))\n",
    "\n",
    "  # Get the predicted and actual labels based on the output of the model\n",
    "  # The numpy argmax() function uses the model's 5 output numbers to get which class the model is predicting\n",
    "  predicted_label = int(np.argmax(predictions))\n",
    "  actual_label = int(label)\n",
    "\n",
    "  # Convert the TensorFlow tensor to a NumPy array so that it can be displayed\n",
    "  image_np = image.numpy()\n",
    "\n",
    "  # Dictionary to get the corresponding animal names from the number labels when plotting\n",
    "  number_to_label = {0: \"bee\",\n",
    "                    1: \"bison\",\n",
    "                    2: \"beetle\",\n",
    "                    3: \"boar\",\n",
    "                    4: \"butterfly\"}\n",
    "\n",
    "  # Plot the image with the predicted label\n",
    "  plt.imshow(image_np)\n",
    "  plt.title(f\"Predicted label: {number_to_label[predicted_label]}\\n Actual label: {number_to_label[actual_label]}\")\n",
    "  plt.axis('off')  # Hide axes for better visualization\n",
    "  plt.show()\n",
    "\n",
    "  # Return the numbers of the predicted and actual labels (more useful than the animal names)\n",
    "  return (predicted_label, actual_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(num_images, num_images_per_category, images, labels):\n",
    "  num_categories = int(num_images/num_images_per_category)\n",
    "\n",
    "  # Initialize counters\n",
    "  wrong = 0\n",
    "  wrong_per_group = []\n",
    "  tp = 0  # True positives, used for precision - explained in the appendix\n",
    "  tp_per_group = []  # True positives per group, used for precision\n",
    "  fp_per_group = [0 for c in range(num_categories)]  # False positives per group, used for precision\n",
    "\n",
    "  # Iterate through all the images\n",
    "  for i in range(num_images):\n",
    "    # Get the predicted and actual labels from the visualization function defined previously\n",
    "    predicted_label, actual_label = visualize_results(images[i], labels[i])\n",
    "\n",
    "    # Check if the model's prediction matches the actual label and update the counters as necessary\n",
    "    if predicted_label == actual_label:\n",
    "      tp += 1\n",
    "    else:\n",
    "      wrong += 1\n",
    "      fp_per_group[predicted_label] += 1\n",
    "    if i%num_images_per_category == num_images_per_category-1:\n",
    "      wrong_per_group.append(wrong)\n",
    "      wrong = 0\n",
    "      tp_per_group.append(tp)\n",
    "      tp = 0\n",
    "\n",
    "  # Divide the total amount wrong by the total amount of images and assign the resulting accuracy\n",
    "  accuracy = 100 - 100*sum(wrong_per_group)/num_images\n",
    "\n",
    "  # Do a similar operation to get a list of accuracies for each group\n",
    "  accuracy_per_group = []\n",
    "  for w in wrong_per_group:\n",
    "    accuracy_per_group.append(100 - 100*w/num_images_per_category)\n",
    "\n",
    "  # Use the precision formula to get overall precision and precision per group\n",
    "  precision = 100*sum(tp_per_group)/(sum(tp_per_group)+sum(fp_per_group))\n",
    "  precision_per_group = []\n",
    "  for c in range(num_categories):\n",
    "    precision_per_group.append(100*tp_per_group[c]/(tp_per_group[c]+fp_per_group[c]))\n",
    "\n",
    "  # Return the overall accuracy and list of accuracies per group, and the overall precision and list of precisions per group\n",
    "  return accuracy, accuracy_per_group, precision, precision_per_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = int(images_per_category*total_train_percentage*categories/100)\n",
    "train_images_per_category = int(images_per_category*total_train_percentage/100)\n",
    "train_accuracy, train_accuracy_per_group, train_precision, train_precision_per_group = get_metrics(\n",
    "train_images, train_images_per_category, train_image, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training Data Overall Accuracy: {train_accuracy}%')\n",
    "\n",
    "# This loop iterates over the list where each element is accuracy for the group\n",
    "for index in range(len(train_accuracy_per_group)):\n",
    "  # Print the accuracy for the group corresponding to the current element\n",
    "  print(f'Training Data Accuracy for {number_to_label[index].title()}: {train_accuracy_per_group[index]}%')\n",
    "\n",
    "print(f'\\nTraining Data Overall Precision: {train_precision}%')\n",
    "\n",
    "# This loop iterates over the list where each element is accuracy for the group\n",
    "for index in range(len(train_precision_per_group)):\n",
    "  # Print the accuracy for the group corresponding to the current element\n",
    "  print(f'Training Data Precision for {number_to_label[index].title()}: {train_precision_per_group[index]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the same code used for the training data, just with a few variables renamed\n",
    "# The only real change here is to define and use total_test_percentage instead of total_train_percentage\n",
    "total_test_percentage = 100-total_train_percentage\n",
    "test_images = int(images_per_category*total_test_percentage*categories/100)\n",
    "test_images_per_category = int(images_per_category*total_test_percentage/100)\n",
    "test_accuracy, test_accuracy_per_group, test_precision, test_precision_per_group = get_metrics(\n",
    "test_images, test_images_per_category, test_image, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same setup for the testing data as we did for the training data above\n",
    "print(f'Testing Data Overall Accuracy: {test_accuracy}%')\n",
    "\n",
    "for index in range(len(test_accuracy_per_group)):\n",
    "    print(f'Testing Data Accuracy for {number_to_label[index].title()}: {test_accuracy_per_group[index]}%')\n",
    "\n",
    "print(f'\\nTesting Data Overall Precision: {test_precision}%')\n",
    "\n",
    "for index in range(len(test_precision_per_group)):\n",
    "    print(f'Testing Data Precision for {number_to_label[index].title()}: {test_precision_per_group[index]}%')"
   ]
  }
 ]
}